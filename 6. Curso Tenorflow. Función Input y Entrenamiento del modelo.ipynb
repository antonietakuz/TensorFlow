{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "from IPython.core import display as ICD\n",
    "from matplotlib  import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.data as tf_data\n",
    "from tensorflow.keras import optimizers\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de los precios de la vivienda con regresión lineal \n",
    " **Aprendizaje automático desde cero (Parte II)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: cargamos el data frame\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "california_housing_dataframe =  pd.read_csv(\"C:/Users/Usuario/Archivos en Jupyter/Tensorflow/input/housing.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 2: separamos los datos de entrenamiento y prueba\n",
    "myfeature =california_housing_dataframe[[\"total_rooms\"]]\n",
    "feature_columns = [tf.feature_column.numeric_column(\"total_rooms\")] \n",
    "targets = california_housing_dataframe[\"median_house_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 3: definimos el optimizador\n",
    "my_optimizer = optimizers.SGD(learning_rate=0.0000001, clipnorm=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 4: definimos el modelo de regresión\n",
    "linear_regresor =tf.estimator.LinearRegressor(\n",
    "    feature_columns=feature_columns,\n",
    "    optimizer=my_optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 5: definimos la función input\n",
    "#Input , devuelven la forma del tensor en el tiempo de construcción, que puede ser parcialmente desconocida.\n",
    "\n",
    "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "    \"\"\"Entrena un modelo de regresión lineal.\n",
    "  \n",
    "    Argumentos:\n",
    "      features: pandas DataFrame de características\n",
    "      target: pandas DataFrame de objetivos\n",
    "      batch_size: Tamaño de los lotes a pasar al modelo\n",
    "      shuffle: Verdadero o Falso. Ya sea para mezclar los datos.\n",
    "      num_epochs: Número de épocas para las que se deben repetir los datos. Ninguno = repetir indefinidamente\n",
    "    Devoluciones:\n",
    "      Tupla de (características, etiquetas) para el siguiente lote de datos\n",
    "    \"\"\"\n",
    "  \n",
    "    # Convierta los datos de pandas en un diccionario de matrices np.\n",
    "    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n",
    " \n",
    "    # Construct a dataset, and configure batching/repeating.\n",
    "    ds = tf.compat.v1.data.Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    # Shuffle the data, if specified.\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(buffer_size=10000)\n",
    "    \n",
    "    # Return the next batch of data.\n",
    "    features, labels = ds.make_one_shot_iterator().get_next()\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer_v1.py:1684: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# Paso 6: entrenar el modelo\n",
    "\n",
    "# _ Almacenar el valor de la última expresión en intérprete.\n",
    "_ = linear_regresor.train(\n",
    "    input_fn = lambda:my_input_fn(myfeature, targets), # Lambda  son una forma corta de declarar funciones pequeñas y anónimas\n",
    "    steps=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio (MSE) en datos de entrenamiento: 56104774069.783\n",
      "Raíz del error cuadrático medio (RMSE) en datos de entrenamiento: 236864.464\n"
     ]
    }
   ],
   "source": [
    "# Paso 7: Evaluar el modelo\n",
    "\n",
    "# crear una función input para prediccciones\n",
    "# Nota: como solo se va a hacer una predicción para cada ejemplo\n",
    "# no tenemos que repetir o mezclar los datops aqui\n",
    "\n",
    "prediction_input_fn =lambda: my_input_fn(myfeature, targets, num_epochs=1, shuffle=False)\n",
    "\n",
    "# llamar a predict() en el linear_regresor para hacer las predicciones\n",
    "predictions = linear_regresor.predict(input_fn=prediction_input_fn)\n",
    "\n",
    "# Formateamos las predicciones como un array np para que podamos calcular las métricas de error\n",
    "predictions = np.array([item['predictions'][0] for item in predictions])\n",
    "\n",
    "# imprimimos el error cuadrático medio y raiz error cuadratico medio\n",
    "mean_squared_error = metrics.mean_squared_error(predictions, targets)\n",
    "root_mean_squared_error = math.sqrt(mean_squared_error)\n",
    "print(\"Error cuadrático medio (MSE) en datos de entrenamiento: %0.3f\" % mean_squared_error)\n",
    "print(\"Raíz del error cuadrático medio (RMSE) en datos de entrenamiento: %0.3f\" % root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimo valor de casa: 14999.000\n",
      "Maximo valor de casa: 500001.000\n",
      "Diferencia entre el maximo y el minimo: 485002.000\n",
      "La diferencia entre el maximo y el minimo es: 236864.464\n"
     ]
    }
   ],
   "source": [
    "# Comparamos el RMSE con min y max de nuestros targets\n",
    "\n",
    "min_house_value = california_housing_dataframe[\"median_house_value\"].min()\n",
    "max_house_value = california_housing_dataframe[\"median_house_value\"].max()\n",
    "min_max_difference = max_house_value - min_house_value\n",
    "\n",
    "print(\"Minimo valor de casa: %0.3f\" % min_house_value)\n",
    "print(\"Maximo valor de casa: %0.3f\" % max_house_value)\n",
    "print(\"Diferencia entre el maximo y el minimo: %0.3f\" % min_max_difference)\n",
    "print(\"La diferencia entre el maximo y el minimo es: %0.3f\" % root_mean_squared_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e06ff7da33dc9620448857a90ad8b5f428f0d573d205a934d2841c8aee45ea32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
